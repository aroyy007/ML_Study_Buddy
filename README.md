# ü§ñ ML Study Buddy - AI-Powered Machine Learning Assistant

A comprehensive Retrieval-Augmented Generation (RAG) system designed to help students master machine learning concepts through intelligent document retrieval, voice interaction, and fine-tuned embeddings.

## üåü Overview

ML Study Buddy is a full-stack application that combines a **Next.js frontend** with a **FastAPI backend** to create an intelligent study companion. The system uses advanced RAG techniques with fine-tuned embeddings to provide accurate, contextual answers to machine learning questions.

### Key Features

- üìö **Intelligent Document Processing**: Supports PDFs, images, and web content with OCR capabilities
- üé§ **Voice Interaction**: Speech-to-text and text-to-speech for hands-free learning
- üéØ **Fine-Tuned Embeddings**: Custom embedding models optimized for ML domain
- üìä **Performance Evaluation**: Comprehensive metrics (Recall@K, MRR, NDCG)
- üåê **Modern Web Interface**: Responsive React UI with real-time chat
- üöÄ **Production Ready**: Deployed on Render with Vercel frontend

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Frontend      ‚îÇ    ‚îÇ    Backend      ‚îÇ    ‚îÇ   AI Services   ‚îÇ
‚îÇ   (Next.js)     ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ   (FastAPI)     ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ   (Groq/HF)     ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ
‚îÇ ‚Ä¢ React UI      ‚îÇ    ‚îÇ ‚Ä¢ RAG Pipeline  ‚îÇ    ‚îÇ ‚Ä¢ Llama 3.3 70B ‚îÇ
‚îÇ ‚Ä¢ Voice Input   ‚îÇ    ‚îÇ ‚Ä¢ Vector Store  ‚îÇ    ‚îÇ ‚Ä¢ Whisper STT   ‚îÇ
‚îÇ ‚Ä¢ Chat Interface‚îÇ    ‚îÇ ‚Ä¢ OCR Processing‚îÇ    ‚îÇ ‚Ä¢ SpeechT5 TTS  ‚îÇ
‚îÇ ‚Ä¢ File Upload   ‚îÇ    ‚îÇ ‚Ä¢ Voice Handler ‚îÇ    ‚îÇ ‚Ä¢ TrOCR         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìä RAG Pipeline

### 1. Document Ingestion
```
Raw Documents ‚Üí Text Extraction ‚Üí Chunking ‚Üí Embedding ‚Üí Vector Store
     ‚Üì              ‚Üì              ‚Üì          ‚Üì           ‚Üì
‚Ä¢ PDFs         ‚Ä¢ PyMuPDF      ‚Ä¢ 1000 chars ‚Ä¢ HuggingFace ‚Ä¢ FAISS
‚Ä¢ Images       ‚Ä¢ TrOCR        ‚Ä¢ 200 overlap ‚Ä¢ all-MiniLM  ‚Ä¢ Index
‚Ä¢ Web Pages    ‚Ä¢ BeautifulSoup‚Ä¢ Recursive   ‚Ä¢ L6-v2       ‚Ä¢ Persist
```

### 2. Query Processing
```
User Query ‚Üí Embedding ‚Üí Similarity Search ‚Üí Context Retrieval ‚Üí LLM Generation
    ‚Üì           ‚Üì            ‚Üì                 ‚Üì               ‚Üì
‚Ä¢ Text/Voice ‚Ä¢ Same Model  ‚Ä¢ Top-K Results  ‚Ä¢ Relevant Docs ‚Ä¢ Groq Llama
‚Ä¢ Image OCR  ‚Ä¢ as Docs     ‚Ä¢ Cosine Sim     ‚Ä¢ Metadata      ‚Ä¢ 3.3 70B
```

### 3. Fine-Tuning Pipeline (v2.0)
```
Documents ‚Üí Synthetic Queries ‚Üí Training Pairs ‚Üí Contrastive Learning ‚Üí Fine-tuned Model
    ‚Üì            ‚Üì                 ‚Üì               ‚Üì                    ‚Üì
‚Ä¢ Chunks    ‚Ä¢ Groq LLM        ‚Ä¢ (Q, Doc+, Doc-) ‚Ä¢ MultipleNegatives  ‚Ä¢ Better Retrieval
‚Ä¢ Metadata  ‚Ä¢ 3 per doc       ‚Ä¢ Hard Negatives  ‚Ä¢ RankingLoss        ‚Ä¢ +15-25% metrics
```

## üõ†Ô∏è Technology Stack

### Frontend (Next.js 15)
- **Framework**: Next.js 15 with App Router
- **UI**: React 19, Tailwind CSS, Radix UI
- **Animations**: Framer Motion
- **State**: React Hooks, Context API
- **Voice**: Web Speech API, MediaRecorder
- **Deployment**: Vercel

### Backend (Python FastAPI)
- **Framework**: FastAPI with Uvicorn
- **RAG**: LangChain, FAISS, HuggingFace
- **LLM**: Groq (Llama 3.3 70B Versatile)
- **Embeddings**: sentence-transformers/all-MiniLM-L6-v2
- **OCR**: TrOCR (microsoft/trocr-base-printed)
- **Voice**: Whisper (openai/whisper-small), SpeechT5
- **Deployment**: Render

### AI Models Used

| Component | Model | Purpose | Why This Model |
|-----------|-------|---------|----------------|
| **LLM** | Llama 3.3 70B (Groq) | Answer generation | Fast inference, high quality, free tier |
| **Embeddings** | all-MiniLM-L6-v2 | Document/query encoding | Balanced speed/quality, 384 dimensions |
| **STT** | Whisper Small | Speech transcription | Robust multilingual, good accuracy |
| **TTS** | SpeechT5 | Speech synthesis | Open source, customizable voice |
| **OCR** | TrOCR Base | Image text extraction | Transformer-based, handles printed text |

## üìÅ Project Structure

```
ml-study-buddy/
‚îú‚îÄ‚îÄ üìÅ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ app/                 # Next.js App Router
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layout.tsx          # Root layout
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ page.tsx            # Landing page
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chat/               # Chat interface
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ components/          # React components
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ChatInterface.tsx   # Main chat UI
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ChatInput.tsx       # Input with voice/file
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MessageBubble.tsx   # Message display
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ VoiceResponseOrb.tsx# Voice visualization
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ui/                 # Reusable UI components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ lib/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api.ts              # Backend API calls
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils.ts            # Utilities
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÅ hooks/               # Custom React hooks
‚îÇ   ‚îú‚îÄ‚îÄ package.json                # Dependencies
‚îÇ   ‚îî‚îÄ‚îÄ tailwind.config.js          # Styling config
‚îÇ
‚îú‚îÄ‚îÄ üìÅ backend/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                     # FastAPI app entry
‚îÇ   ‚îú‚îÄ‚îÄ config.py                   # Configuration
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ rag/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chain.py                # RAG chain logic
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vector_store.py         # FAISS management
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ voice/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ handler.py              # Voice processing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stt.py                  # Speech-to-text
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tts.py                  # Text-to-speech
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ ocr/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ processor.py            # Image OCR
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ faiss_index/             # Vector database
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt            # Python dependencies
‚îÇ   ‚îî‚îÄ‚îÄ render.yaml                 # Deployment config
‚îÇ
‚îî‚îÄ‚îÄ üìÅ notebook/
    ‚îú‚îÄ‚îÄ ML_RAG_System_v1_0.ipynb    # Complete RAG system
    ‚îî‚îÄ‚îÄ ML_RAG_System_v2_FineTuned.ipynb # Fine-tuning pipeline
```

## üîÑ Data Flow

### 1. Document Processing Flow
```mermaid
graph TD
    A[Upload Document] --> B{File Type?}
    B -->|PDF| C[PyMuPDF Extract]
    B -->|Image| D[TrOCR Extract]
    B -->|URL| E[Web Scrape]
    C --> F[Text Chunking]
    D --> F
    E --> F
    F --> G[Generate Embeddings]
    G --> H[Store in FAISS]
    H --> I[Update Index]
```

### 2. Query Processing Flow
```mermaid
graph TD
    A[User Query] --> B{Input Type?}
    B -->|Text| C[Direct Processing]
    B -->|Voice| D[Whisper STT]
    B -->|Image| E[TrOCR + Query]
    C --> F[Embed Query]
    D --> F
    E --> F
    F --> G[FAISS Search]
    G --> H[Retrieve Top-K Docs]
    H --> I[Format Context]
    I --> J[Groq LLM]
    J --> K[Generate Response]
    K --> L{Voice Response?}
    L -->|Yes| M[SpeechT5 TTS]
    L -->|No| N[Return Text]
    M --> N
```

### 3. Fine-Tuning Flow (v2.0)
```mermaid
graph TD
    A[Existing Documents] --> B[Generate Synthetic Queries]
    B --> C[Create Training Pairs]
    C --> D[Mine Hard Negatives]
    D --> E[Contrastive Learning]
    E --> F[Fine-tuned Embeddings]
    F --> G[Rebuild FAISS Index]
    G --> H[Evaluate Performance]
    H --> I[Deploy if Better]
```

## üöÄ Quick Start

### Prerequisites
- Node.js 18+
- Python 3.9+
- Groq API Key (free at [console.groq.com](https://console.groq.com))

### 1. Clone Repository
```bash
git clone https://github.com/yourusername/ml-study-buddy.git
cd ml-study-buddy
```

### 2. Backend Setup
```bash
cd backend
pip install -r requirements.txt
cp .env.example .env
# Edit .env with your GROQ_API_KEY
python run.py
```

### 3. Frontend Setup
```bash
cd ../
npm install
npm run dev
```

### 4. Access Application
- Frontend: http://localhost:3000
- Backend API: http://localhost:8000
- API Docs: http://localhost:8000/docs

## üìà Performance Metrics

### Baseline vs Fine-Tuned Embeddings

| Metric | Baseline | Fine-tuned | Improvement |
|--------|----------|------------|-------------|
| **Recall@5** | 0.60 | 0.75-0.82 | +15-22% |
| **MRR@5** | 0.40 | 0.55-0.65 | +15-25% |
| **NDCG@5** | 0.45 | 0.60-0.70 | +15-25% |

### Evaluation Metrics Explained

- **Recall@K**: Fraction of queries where relevant document appears in top-K results
- **MRR (Mean Reciprocal Rank)**: Average of 1/rank of first relevant document
- **NDCG@K**: Normalized Discounted Cumulative Gain, considers ranking quality

## üéØ Fine-Tuning Process

### Why Fine-Tune Embeddings?

1. **Domain Adaptation**: Generic embeddings may not capture ML-specific relationships
2. **Improved Retrieval**: Better semantic understanding of ML concepts
3. **Query-Document Alignment**: Learns to match student questions with relevant content

### Fine-Tuning Pipeline

1. **Synthetic Data Generation**
   - Use Groq LLM to generate 3 queries per document chunk
   - Create (query, positive_document) pairs
   - Generate ~1500 training examples

2. **Contrastive Learning**
   - MultipleNegativesRankingLoss (InfoNCE)
   - In-batch negatives for efficiency
   - Hard negative mining from existing index

3. **Model Training**
   - Base: sentence-transformers/all-MiniLM-L6-v2
   - 3 epochs, batch size 16, learning rate 2e-5
   - Warmup steps: 100

4. **Evaluation & Deployment**
   - Compare metrics on held-out test set
   - Rebuild FAISS index with fine-tuned embeddings
   - A/B test in production

## üîß API Endpoints

### Core Endpoints
- `GET /health` - System health check
- `POST /query` - Text-based RAG query
- `POST /transcribe` - Audio transcription
- `POST /voice-query` - Voice-based RAG query
- `POST /upload` - Document upload
- `DELETE /session/{id}` - Clear chat session

### Request/Response Examples

#### Text Query
```bash
curl -X POST "http://localhost:8000/query" \
  -H "Content-Type: application/json" \
  -d '{"question": "What is gradient descent?", "session_id": "user123"}'
```

#### Voice Query
```bash
curl -X POST "http://localhost:8000/voice-query" \
  -F "audio=@recording.wav" \
  -F "session_id=voice123" \
  -F "generate_audio=true"
```

## üåê Deployment

### Backend (Render)
```yaml
# render.yaml
services:
  - type: web
    name: ml-study-buddy-api
    runtime: python
    buildCommand: pip install -r requirements.txt
    startCommand: uvicorn main:app --host 0.0.0.0 --port $PORT
    envVars:
      - key: GROQ_API_KEY
        sync: false
```

### Frontend (Vercel)
```bash
# Deploy to Vercel
vercel --prod
# Set environment variable
vercel env add NEXT_PUBLIC_API_URL
```

## üß™ Development & Testing

### Running Jupyter Notebooks
```bash
# Install Jupyter
pip install jupyter

# Run v1.0 (Complete RAG System)
jupyter notebook notebook/ML_RAG_System_v1_0.ipynb

# Run v2.0 (Fine-Tuning Pipeline)
jupyter notebook notebook/ML_RAG_System_v2_FineTuned.ipynb
```

### Testing the System
1. **Health Check**: Verify backend is running
2. **Document Upload**: Test PDF/image processing
3. **Text Queries**: Test RAG responses
4. **Voice Features**: Test STT/TTS pipeline
5. **Fine-Tuning**: Run evaluation metrics

## ü§ù Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- **Groq** for fast LLM inference
- **HuggingFace** for open-source models
- **LangChain** for RAG framework
- **FAISS** for efficient vector search
- **Next.js** and **FastAPI** for modern web development

## üìû Support

- üìß Email: support@mlstudybuddy.com
- üí¨ Discord: [Join our community](https://discord.gg/mlstudybuddy)
- üìñ Docs: [Documentation](https://docs.mlstudybuddy.com)
- üêõ Issues: [GitHub Issues](https://github.com/yourusername/ml-study-buddy/issues)

---

**Built with ‚ù§Ô∏è for the ML community**